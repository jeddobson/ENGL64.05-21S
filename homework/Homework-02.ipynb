{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Cultural Analytics: Homework #2</h1></center>\n",
    "<center><h2>ENGL 64.05, 21S</h2></center>\n",
    "<br>\n",
    "<center><b>Due</b> 11:59PM 04/16/2021</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we're in the home directory\n",
    "%cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "import sys\n",
    "sys.path.append('shared/engl64.05/lib')\n",
    "from tsvdro import tsvdro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"Green\"> HW 2.1</font>: Vectorization and Comparison by Genre</h2>\n",
    "\n",
    "<p>You'll need to take a sample of entries from Ted Underwood's metadata and then run through the remainder of the cells in this group and then respond to the prompt.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we're going to load the CSV using Pandas into a DataFrame.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "# \n",
    "# Using a DataFrame will have some obvious benefits, including the automatic reading\n",
    "# of the header row and guessing datatypes for our numerical values (i.e., year of publication)\n",
    "metadata = pd.read_csv(\"shared/engl64.05/data/Underwood_ch1/allgenremeta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"Red\">Sample Data</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample from the metadata using Pandas and assign it to \n",
    "# a variable named \"sample.\" How much data should you sample? \n",
    "# What do you think makes sense?\n",
    "#\n",
    "# See our readings from Monday and https://pandas.pydata.org for help with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example and because the documents provided have already been rendered data\n",
    "# as word frequencies, we'll use the DictVectorizer. This will simply combine the existing \n",
    "# vocabulary.\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = list()\n",
    "for filename in [f + '.dro' for f in sample['docid'].tolist()]:\n",
    "    tmp_data = tsvdro.load(\"shared/engl64.05/data/Underwood_ch1/\" + filename)\n",
    "    doc_data.append(tmp_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize from DRO documents\n",
    "dtm = vectorizer.fit_transform(doc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a distance matrix using Cosine similarity\n",
    "# https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_dist_matrix = 1 - cosine_similarity(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Cosine similarity matrix is the size of sample x sample \n",
    "# We need to reduce this to two dimensions in order to plot the \n",
    "# data. We want to see if we can separate texts by their genre.\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform(cosine_dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# \n",
    "# NOTE: you might need to click on the image to expand it enough to read it. \n",
    "# \n",
    "# Too many objects to read? Modify your sample. \n",
    "# Not enough points? Modify your sample.\n",
    "# \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "fig = plt.figure(figsize=(35, 20), dpi=75)\n",
    "genres = list(sample['genretags'])\n",
    "authors = list(sample['author'])\n",
    "\n",
    "# this will loop through four different lists simultaneously\n",
    "for x, y, genre, author in zip(xs, ys, genres,authors):\n",
    "\n",
    "    # plot the point itsself\n",
    "    plt.scatter(x, y, c='lightgrey',s=6)\n",
    "\n",
    "    # These two lines will annotate the point by displaying \n",
    "    # the genre (in red) and author (in blue). \n",
    "    plt.text(x, y, genre, c=\"red\", ha='center', va='bottom')\n",
    "    plt.text(x, y, author, c=\"blue\", ha='center', va='top')\n",
    "\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response: \n",
    "In no more than two hundred words respond to the following prompt: What do you observe in the above figure? What happens when you rerun these cells? How robust are these results? What questions do you have about the dataset and methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2><font color=\"Green\"> HW 2.2</font>: Vectorization of ASCII Text</h2>\n",
    "\n",
    "Insert a new cell and:\n",
    "1. Vectorize all of the 150 English-language novels in the Novel450 dataset (review Lab 2 notebook)\n",
    "2. No stopwords\n",
    "3. Only include vocabulary that appears in 50% of the texts.\n",
    "4. Your document-term matrix should be called counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give us a set of shorter labels\n",
    "labels = [os.path.basename(f).replace('.txt','') for f in input_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarity\n",
    "cosine_dist_matrix = 1 - cosine_similarity(counts)\n",
    "\n",
    "# Display distance from Pride and Prejudice\n",
    "for x,y in sorted(enumerate(cosine_dist_matrix[5]), key=itemgetter(1)):\n",
    "    print('{0:.4f} {1}'.format(y,labels[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate Euclidean distance\n",
    "from sklearn.metrics import euclidean_distances\n",
    "euclidean_dist_matrix = euclidean_distances(counts)\n",
    "\n",
    "# Display distance from Pride and Prejudice\n",
    "for x,y in sorted(enumerate(euclidean_dist_matrix[5]), key=itemgetter(1)):\n",
    "    print('{0:.2f} {1}'.format(y,labels[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"Red\">Create a Plot</font></h2>\n",
    "Add a new cell that produces a scatter plot of the cosine similarity data (cosine_dist_matrix). Instead of adding author and genre labels (as above), just annotate with the filename lables in the labels dictionary. You can modify the above code to make this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response: \n",
    "In no more than two hundred words respond to the following prompt: What do you observe in the above cells? What differences do you see between the two distance metrics (Cosine similarity and Eucidean distance)? What do you think these methods tell us about modeling semantic space in this novel collection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
